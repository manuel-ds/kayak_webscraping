{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "from datetime import datetime, timedelta, time\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def compute_avg_price():\n",
    "    try:\n",
    "        global avg_price\n",
    "        global price_same_time\n",
    "        global now_string\n",
    "        def make_identifier(df):\n",
    "            str_id = df.apply(lambda x: '_'.join(map(str, x)), axis = 1)\n",
    "            return pd.factorize(str_id)[0]\n",
    "\n",
    "        df_merged = pd.read_csv('df_merged.csv')\n",
    "        df_merged['date_time'] = pd.to_datetime(df_merged['scrape_datetime'], format=\"%d-%m-%Y %H:%M\")\n",
    "        df_merged['duration_outband'] = pd.to_timedelta(df_merged.out_duration)\n",
    "        df_merged['duration_return'] = pd.to_timedelta(df_merged.ret_duration)\n",
    "        df_merged.drop(['out_duration', 'ret_duration', 'scrape_datetime'], axis=1, inplace=True)\n",
    "        df_merged['id'] = make_identifier(df_merged[['Company', 'outband_time', 'return_time', 'stops', 'duration_outband', 'duration_return', 'air_out', 'air_ret']])\n",
    "        df_merged = df_merged.set_index('id')\n",
    "        df_merged['scraped_at'] = df_merged['date_time'].astype('string')\n",
    "        df_merged['scraped_at'] = [int(x[11:13]) for x in df_merged.scraped_at]\n",
    "\n",
    "        avg_price = np.mean(df_merged['Price'])\n",
    "\n",
    "        now = datetime.now()\n",
    "        now_string = int(now.strftime(\"%H\"))\n",
    "\n",
    "        avg_hour_price = df_merged.groupby('scraped_at')['Price'].agg(np.mean).reset_index()\n",
    "        price_same_time = int(avg_hour_price[avg_hour_price.scraped_at == now_string]['Price'].item())\n",
    "    except:\n",
    "        print('I will create a new data frame')\n",
    "    return 'done'\n",
    "\n",
    "\n",
    "def search_flight(departure='MIL', destination='NYC', date_dep='2022-11-28', date_ret='2022-12-02'):\n",
    "    global flight_rows\n",
    "    global companies\n",
    "    global dep\n",
    "    global duration\n",
    "    global flight_hours\n",
    "    global df\n",
    "    global new_avg_price\n",
    "    global advice_list\n",
    "    \n",
    "    # libraries\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.keys import Keys\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    import time\n",
    "    import os\n",
    "    import re\n",
    "\n",
    "    PATH = \"/Users/manueldona/chromedriver\"\n",
    "    driver = webdriver.Chrome(PATH)\n",
    "\n",
    "    link = 'https://www.kayak.it/flights/{departure}-{destination}/{date_dep}/{date_ret}?sort=bestflight_a'.format(departure=departure,destination=destination, date_dep=date_dep, date_ret=date_ret)\n",
    "    driver.get(link)\n",
    "\n",
    "    time.sleep(10)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//div[@class = \"dDYU-close dDYU-mod-variant-default dDYU-mod-size-default\"]'))\n",
    "        )\n",
    "        time.sleep(2)\n",
    "        element.click() \n",
    "        \n",
    "        time.sleep(20)\n",
    "\n",
    "        flight_rows = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_all_elements_located((By.XPATH, '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"multi-row\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"option-text\", \" \" ))]'))\n",
    "        )\n",
    "\n",
    "\n",
    "        companies = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_all_elements_located((By.XPATH, '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"codeshares-airline-names\", \" \" ))]'))\n",
    "        )\n",
    "\n",
    "        dep = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_all_elements_located((By.XPATH, '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"times\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"top\", \" \" ))]'))\n",
    "        )\n",
    "\n",
    "\n",
    "        duration = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_all_elements_located((By.XPATH, '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"stops\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"top\", \" \" ))]'))\n",
    "        )\n",
    "\n",
    "\n",
    "        flight_hours = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_all_elements_located((By.XPATH, '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"allow-multi-modal-icons\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"top\", \" \" ))]'))\n",
    "        )\n",
    "\n",
    "\n",
    "        airport = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_all_elements_located((By.XPATH, '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"times\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"bottom\", \" \" ))]'))\n",
    "        )\n",
    "\n",
    "        advice = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, '//*[contains(@id, \"advice\") and contains(@class, \"value\") and contains(@aria-busy, \"false\")]'))\n",
    "        )\n",
    "        \n",
    "\n",
    "    except:\n",
    "        driver.quit()\n",
    "        \n",
    "    \n",
    "    time.sleep(7)\n",
    "\n",
    "    # flight prices \n",
    "    try:\n",
    "\n",
    "        prices_list = []\n",
    "\n",
    "        for WebElement in flight_rows:\n",
    "            elementHTML = WebElement.get_attribute('outerHTML')\n",
    "            elementSoup = BeautifulSoup(elementHTML, 'html.parser')\n",
    "            p = elementSoup.find(\"span\", {\"class\": \"price-text\"})\n",
    "            prices_list.append(p.text)\n",
    "\n",
    "        prices = re.findall(r'\\d{1,3}', str(prices_list))\n",
    "        prices = [int(price) for price in prices]\n",
    "\n",
    "\n",
    "        time.sleep(7)\n",
    "\n",
    "        # company name\n",
    "\n",
    "        companies_list = []\n",
    "\n",
    "        for WebElement in companies:\n",
    "            elementHTML = WebElement.get_attribute('outerHTML')\n",
    "            elementSoup = BeautifulSoup(elementHTML, 'html.parser')\n",
    "            c = elementSoup.find(\"span\", {\"class\": \"codeshares-airline-names\"})\n",
    "            companies_list.append(c.text)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "\n",
    "        # flight time schedules\n",
    "        dep_time = []\n",
    "\n",
    "        for WebElement in dep:\n",
    "            elementHTML = WebElement.get_attribute('outerHTML')\n",
    "            elementSoup = BeautifulSoup(elementHTML, 'html.parser')\n",
    "            d = elementSoup.find(\"div\", {\"class\": \"top\"})\n",
    "            dep_time.append(d.text)\n",
    "\n",
    "        times = re.findall('\\d{1,2}:\\d\\d', str(dep_time))\n",
    "\n",
    "        times = [times[i:i+2] for i in range(0,len(times),2)]\n",
    "\n",
    "        out = times[0::2]\n",
    "        out = ['-'.join(x) for x in out]\n",
    "\n",
    "        ret = times[1::2]\n",
    "        ret = ['-'.join(x) for x in ret]\n",
    "\n",
    "        # flight info's\n",
    "        info = []\n",
    "\n",
    "        for WebElement in duration:\n",
    "            elementHTML = WebElement.get_attribute('outerHTML')\n",
    "            elementSoup = BeautifulSoup(elementHTML, 'html.parser')\n",
    "            i = elementSoup.find(\"span\", {\"class\": \"stops-text\"})\n",
    "            info.append(i.text.strip())\n",
    "\n",
    "        time.sleep(4)\n",
    "\n",
    "        # flight hours\n",
    "        hours = []\n",
    "\n",
    "        for WebElement in flight_hours:\n",
    "            elementHTML = WebElement.get_attribute('outerHTML')\n",
    "            elementSoup = BeautifulSoup(elementHTML, 'html.parser')\n",
    "            h = elementSoup.find(\"div\", {\"class\": \"top\"})\n",
    "            hours.append(h.text.strip())\n",
    "\n",
    "        out_dur = hours[0::2]\n",
    "        ret_dur = hours[1::2]\n",
    "\n",
    "    \n",
    "        # airport name\n",
    "\n",
    "        airports = []\n",
    "\n",
    "        for WebElement in airport:\n",
    "            elementHTML = WebElement.get_attribute('outerHTML')\n",
    "            elementSoup = BeautifulSoup(elementHTML, 'html.parser')\n",
    "            a = elementSoup.find(\"div\", {\"class\": \"bottom\"})\n",
    "            airports.append(a.text.strip())\n",
    "\n",
    "        air = re.findall('[A-Z]{3}', str(airports))\n",
    "\n",
    "        air_out_ret = [air[i:i+2] for i in range(0,len(air),2)]\n",
    "\n",
    "        air_out = air_out_ret[0::2]\n",
    "        air_out = ['-'.join(x) for x in air_out]\n",
    "\n",
    "        air_ret = air_out_ret[1::2]\n",
    "        air_ret = ['-'.join(x) for x in air_ret]\n",
    "        \n",
    "        # advice \n",
    "        advice_list = \"\"\n",
    "\n",
    "        elementHTML = advice.get_attribute('outerHTML')\n",
    "        elementSoup = BeautifulSoup(elementHTML, 'html.parser')\n",
    "        ad = elementSoup.find(\"div\", {\"class\": \"value\"})\n",
    "        advice_list = ad.text.strip()\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    # df creation\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(list(zip(companies_list, prices, out, ret, info, out_dur, ret_dur, air_out, air_ret)),\n",
    "                       columns =['Company', 'Price', 'outband_time', 'return_time', 'stops', 'out_duration', 'ret_duration', 'air_out', 'air_ret'])\n",
    "\n",
    "    def make_identifier(df):\n",
    "        str_id = df.apply(lambda x: '_'.join(map(str, x)), axis = 1)\n",
    "        return pd.factorize(str_id)[0]\n",
    "\n",
    "    df['combined_id'] = make_identifier(df[['Company', 'outband_time', 'return_time', 'stops', 'out_duration', 'ret_duration', 'air_out', 'air_ret']])\n",
    "    \n",
    "    df = df.sort_values('Price').drop_duplicates(subset=['combined_id'])\n",
    "    \n",
    "    df = df.iloc[:, :-1]\n",
    "    \n",
    "    from datetime import datetime\n",
    "\n",
    "    now = datetime.now()\n",
    "\n",
    "    # dd/mm/YY H:M:S\n",
    "    dt_string_save = now.strftime(\"%d-%m-%Y_%H-%M\")\n",
    "    dt_string_df = now.strftime(\"%d-%m-%Y %H:%M\")\n",
    "    \n",
    "    df['scrape_datetime'] = dt_string_df # adding scrape datetime to df\n",
    "\n",
    "    df.to_csv('flights_{departure}_{destination}_{now}.csv'.format(departure=departure, destination=destination, now=dt_string_save), index=False)\n",
    "    \n",
    "    # saving avg price of df\n",
    "    new_avg_price = np.mean(df['Price'])\n",
    "    \n",
    "    # adding new data to df_merged\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "def add_newdata():\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "\n",
    "    global df_merged \n",
    "    \n",
    "    now = datetime.now()\n",
    "    dt_string_save = now.strftime(\"%d-%m-%Y_%H-%M\")\n",
    "    \n",
    "    if os.path.exists('/Users/manueldona/df_merged.csv'):  # path for existing df_merged\n",
    "        flights = pd.read_csv('df_merged.csv')\n",
    "        print('I am adding df to the already existig data_merged.csv file')\n",
    "    else:\n",
    "        flights = pd.DataFrame() # creating a df_merged if it doesn't exist\n",
    "        print('I am creating a new file called data_merged.csv')\n",
    "    \n",
    "    time.sleep(3) \n",
    "    \n",
    "    df_merged = pd.concat([flights, df], axis=0, ignore_index=True) # adding new scraped data to df_merged\n",
    "    df_merged.to_csv('df_merged.csv'.format(dt_string=dt_string_save), index=False) # saving changes to df_merged\n",
    "    return(df_merged)\n",
    "        \n",
    "\n",
    "def sendmail():\n",
    "    \n",
    "    import smtplib\n",
    "\n",
    "    # Import the email modules we'll need\n",
    "    from email.message import EmailMessage\n",
    "\n",
    "    import ssl\n",
    "    \n",
    "    try:\n",
    "        var = (new_avg_price - avg_price)/avg_price\n",
    "\n",
    "        var_same_time = (new_avg_price - price_same_time)/price_same_time\n",
    "\n",
    "        if new_avg_price >= avg_price:\n",
    "            string = 'At this time the mean price of {:.2f} is {:.2%} higher than usual.'.format(new_avg_price, var)\n",
    "        else:\n",
    "            string = 'At this time the mean price of {:.2f} is {:.2%} lower than usual.'.format(new_avg_price, var)\n",
    "\n",
    "        if int(new_avg_price) >= int(price_same_time):\n",
    "            string_2 = 'Usually at {} the price is {:.2%} lower'.format(now_string, var_same_time)\n",
    "        else:\n",
    "            string_2 = 'Usually at {} the price is {:.2%} lower'.format(now_string, var_same_time)\n",
    "            \n",
    "        body = \"\"\"{string} {string_2}, the advice of kayak is: {}\"\"\".format(string=string, string_2=string_2, advice_list)\n",
    "    \n",
    "    except:\n",
    "        body = \"\"\" I created a new data frame, now the average price is {:.2f}\"\"\".format(new_avg_price)\n",
    "\n",
    "    email_sender = 'manu.md28@gmail.com'\n",
    "    email_password = 'yegtifflhrkcjmzl'\n",
    "    email_receiver = 'm.dona1@studenti.unibg.it'\n",
    "\n",
    "    subject = 'Flight prices update'\n",
    "\n",
    "    em = EmailMessage()\n",
    "    em['From'] = email_sender\n",
    "    em['To'] = email_receiver\n",
    "    em['Subject'] = subject\n",
    "    em.set_content(body)\n",
    "\n",
    "    context = ssl.create_default_context()\n",
    "\n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com', 465, context=context) as smtp:\n",
    "        smtp.login(email_sender, email_password)\n",
    "        smtp.sendmail(email_sender, email_receiver, em.as_string())\n",
    "    return 'e-mail sent!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01afe53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduling the search_flight and add_newdata functions\n",
    "from datetime import datetime\n",
    "def job():\n",
    "    compute_avg_price()\n",
    "    time.sleep(1)\n",
    "    search_flight()\n",
    "    time.sleep(2)\n",
    "    sendmail()\n",
    "    time.sleep(1)\n",
    "    add_newdata()\n",
    "    print('Email sent')\n",
    "\n",
    "schedule.every(3).hours.at(\":30\").do(job)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(3)\n",
    "    now = datetime.now()\n",
    "    now_string = now.strftime(\"%d-%m-%Y %H:%M\")\n",
    "    if now_string == \"31-10-2022 23:45\":\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
